{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95032d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f8a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32113c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def perform_sentiment_analysis(text):\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "    # Perform sentiment analysis\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3c2cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text for sentiment analysis (type 'exit' to quit): Its been an amazing day\n",
      "Positive sentiment\n",
      "Enter text for sentiment analysis (type 'exit' to quit): I went to buy milk\n",
      "Neutral sentiment\n",
      "Enter text for sentiment analysis (type 'exit' to quit): Its been an boring day\n",
      "Negative sentiment\n",
      "Enter text for sentiment analysis (type 'exit' to quit): exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    while True:\n",
    "        # Prompt user to input text\n",
    "        text = input(\"Enter text for sentiment analysis (type 'exit' to quit): \")\n",
    "        \n",
    "        # Check if user wants to exit\n",
    "        if text.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        \n",
    "        # Perform sentiment analysis\n",
    "        sentiment = perform_sentiment_analysis(text)\n",
    "        \n",
    "        # Determine sentiment category based on polarity score\n",
    "        if sentiment > 0:\n",
    "            print(\"Positive sentiment\")\n",
    "        elif sentiment < 0:\n",
    "            print(\"Negative sentiment\")\n",
    "        else:\n",
    "            print(\"Neutral sentiment\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next word Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ffd61f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 5s 116ms/step - loss: 5.4473 - accuracy: 0.0223\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 5.2830 - accuracy: 0.0362\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 126ms/step - loss: 5.1574 - accuracy: 0.0362\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 5.0903 - accuracy: 0.0362\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 5.0627 - accuracy: 0.0418\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 5.0476 - accuracy: 0.0585\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 5.0165 - accuracy: 0.0585\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 4.9717 - accuracy: 0.0529\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 4.9184 - accuracy: 0.0669\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 4.8363 - accuracy: 0.0780\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 4.7570 - accuracy: 0.0780\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 4.7053 - accuracy: 0.0752\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 4.6053 - accuracy: 0.0836\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 4.5245 - accuracy: 0.0808\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 4.4235 - accuracy: 0.0864\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 4.3389 - accuracy: 0.0947\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 4.2339 - accuracy: 0.1003\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 4.0930 - accuracy: 0.1114\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 4.0019 - accuracy: 0.1198\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 3.8118 - accuracy: 0.1588\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 3.6509 - accuracy: 0.1783\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 3.4912 - accuracy: 0.2201\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 3.3339 - accuracy: 0.2340\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 3.1857 - accuracy: 0.2312\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 3.0225 - accuracy: 0.2646\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 2.8468 - accuracy: 0.3120\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 2.7024 - accuracy: 0.3398\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 2.5819 - accuracy: 0.3733\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 2.4357 - accuracy: 0.4178\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 2.3016 - accuracy: 0.4680\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 2.1893 - accuracy: 0.4763\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 2.0601 - accuracy: 0.5710\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 2.0039 - accuracy: 0.5850\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 1.8844 - accuracy: 0.6072\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 1.7708 - accuracy: 0.6602\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1.6746 - accuracy: 0.6880\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 1.5969 - accuracy: 0.7270\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 1.5186 - accuracy: 0.7632\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 1.4476 - accuracy: 0.8050\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 1.3750 - accuracy: 0.8217\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 1.3123 - accuracy: 0.8440\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 1.2439 - accuracy: 0.8774\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1.1781 - accuracy: 0.8997\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 1.1268 - accuracy: 0.9053\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 1.0707 - accuracy: 0.9136\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 1.0200 - accuracy: 0.9248\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.9627 - accuracy: 0.9220\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.9271 - accuracy: 0.9415\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.8773 - accuracy: 0.9526\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.8513 - accuracy: 0.9499\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.8043 - accuracy: 0.9471\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 2s 124ms/step - loss: 0.7505 - accuracy: 0.9638\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.7176 - accuracy: 0.9638\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.6847 - accuracy: 0.9666\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.6534 - accuracy: 0.9805\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.6274 - accuracy: 0.9805\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.5957 - accuracy: 0.9833\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.5735 - accuracy: 0.9721\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.5429 - accuracy: 0.9805\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.5184 - accuracy: 0.9861\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.4969 - accuracy: 0.9833\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.4722 - accuracy: 0.9861\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.4542 - accuracy: 0.9861\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.4340 - accuracy: 0.9889\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.4172 - accuracy: 0.9889\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.3999 - accuracy: 0.9833\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.3859 - accuracy: 0.9833\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.3704 - accuracy: 0.9861\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.3590 - accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.3373 - accuracy: 0.9916\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.3220 - accuracy: 0.9916\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.3073 - accuracy: 0.9916\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.2954 - accuracy: 0.9889\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.2856 - accuracy: 0.9889\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.2741 - accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.2646 - accuracy: 0.9861\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.2550 - accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.2465 - accuracy: 0.9889\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.2362 - accuracy: 0.9889\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.2302 - accuracy: 0.9861\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.2206 - accuracy: 0.9833\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2131 - accuracy: 0.9916\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.2070 - accuracy: 0.9916\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.2003 - accuracy: 0.9916\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1941 - accuracy: 0.9916\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1870 - accuracy: 0.9861\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1806 - accuracy: 0.9889\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1754 - accuracy: 0.9889\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1752 - accuracy: 0.9861\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1670 - accuracy: 0.9889\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1621 - accuracy: 0.9861\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1625 - accuracy: 0.9889\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1563 - accuracy: 0.9833\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1487 - accuracy: 0.9889\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1438 - accuracy: 0.9861\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1399 - accuracy: 0.9916\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 124ms/step - loss: 0.1348 - accuracy: 0.9889\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1317 - accuracy: 0.9861\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1274 - accuracy: 0.9916\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1246 - accuracy: 0.9916\n",
      "1/1 [==============================] - 1s 814ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Next predicted words:  Pizza is undoubtedly one of the world's most beloved\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "def file_to_sentence_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Splitting the text into sentences using\n",
    "    # delimiters like '.', '?', and '!'\n",
    "    sentences = [sentence.strip() for sentence in re.split(r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
    "\n",
    "    return sentences\n",
    "\n",
    "file_path = \"C:/Users/ADMIN/Documents/pizza.txt\"\n",
    "text_data = file_to_sentence_list(file_path)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences and split into predictors and label\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(\n",
    "    input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "\n",
    "# Convert target data to one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    LSTM(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)\n",
    "\n",
    "# Generate next word predictions\n",
    "seed_text = \" Pizza is undoubtedly one\"\n",
    "next_words = 5\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences(\n",
    "        [token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list)\n",
    "    predicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
    "    seed_text += \" \" + predicted_word\n",
    "\n",
    "print(\"Next predicted words:\", seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebba358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 8s 135ms/step - loss: 5.4474 - accuracy: 0.0223\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 5.2892 - accuracy: 0.0418\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 5.1622 - accuracy: 0.0418\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 5.0874 - accuracy: 0.0529\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 5.0701 - accuracy: 0.0390\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 5.0539 - accuracy: 0.0474\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 5.0383 - accuracy: 0.0501\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 5.0265 - accuracy: 0.0418\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 4.9872 - accuracy: 0.0808\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 4.9376 - accuracy: 0.0752\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 4.8554 - accuracy: 0.0585\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 4.7829 - accuracy: 0.0752\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 4.6793 - accuracy: 0.0808\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 4.5631 - accuracy: 0.0808\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 4.4578 - accuracy: 0.0919\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 4.3101 - accuracy: 0.0975\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 4.1605 - accuracy: 0.0975\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 4.0369 - accuracy: 0.1253\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 3.8457 - accuracy: 0.1504\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 3.6786 - accuracy: 0.1838\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 3.5191 - accuracy: 0.1811\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 124ms/step - loss: 3.3226 - accuracy: 0.2006\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 3.1721 - accuracy: 0.2117\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 2.9802 - accuracy: 0.2786\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 2.7993 - accuracy: 0.3064\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 2.6464 - accuracy: 0.3203\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 2.4810 - accuracy: 0.4011\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 2.3471 - accuracy: 0.4429\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 2.2045 - accuracy: 0.5070\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 2.0905 - accuracy: 0.4986\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1.9676 - accuracy: 0.5655\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 1.8752 - accuracy: 0.5877\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 1.7670 - accuracy: 0.6435\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 1.6685 - accuracy: 0.6713\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 3s 219ms/step - loss: 1.5794 - accuracy: 0.7270\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 1.4864 - accuracy: 0.7716\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 1.4140 - accuracy: 0.8022\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 1.3351 - accuracy: 0.8078\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 174ms/step - loss: 1.2586 - accuracy: 0.8552\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1.1925 - accuracy: 0.8691\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 2s 197ms/step - loss: 1.1289 - accuracy: 0.8802\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 1.0660 - accuracy: 0.8969\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 1.0268 - accuracy: 0.9081\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.9684 - accuracy: 0.9220\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.9301 - accuracy: 0.9415\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.8706 - accuracy: 0.9499\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.8399 - accuracy: 0.9499\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.7964 - accuracy: 0.9471\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.7613 - accuracy: 0.9499\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 0.7296 - accuracy: 0.9499\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.6882 - accuracy: 0.9666\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.6545 - accuracy: 0.9749\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.6179 - accuracy: 0.9694\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5923 - accuracy: 0.9749\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 0.5624 - accuracy: 0.9833\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.5381 - accuracy: 0.9805\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.5227 - accuracy: 0.9805\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.4922 - accuracy: 0.9861\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.4701 - accuracy: 0.9889\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 0.4525 - accuracy: 0.9889\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.4308 - accuracy: 0.9916\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.4127 - accuracy: 0.9861\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.3919 - accuracy: 0.9861\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.3771 - accuracy: 0.9833\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.3633 - accuracy: 0.9833\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.3521 - accuracy: 0.9861\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.3366 - accuracy: 0.9861\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.3203 - accuracy: 0.9861\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.3078 - accuracy: 0.9889\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.3010 - accuracy: 0.9861\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2843 - accuracy: 0.9861\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.2729 - accuracy: 0.9889\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.2616 - accuracy: 0.9889\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.2511 - accuracy: 0.9861\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.2428 - accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.2329 - accuracy: 0.9916\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.2246 - accuracy: 0.9889\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.2176 - accuracy: 0.9916\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.2098 - accuracy: 0.9916\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.2025 - accuracy: 0.9889\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 2s 123ms/step - loss: 0.1969 - accuracy: 0.9916\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.1936 - accuracy: 0.9916\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1904 - accuracy: 0.9889\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.1804 - accuracy: 0.9916\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1728 - accuracy: 0.9889\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1655 - accuracy: 0.9889\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1592 - accuracy: 0.9916\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1548 - accuracy: 0.9889\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 0.1510 - accuracy: 0.9889\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.1459 - accuracy: 0.9889\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.1414 - accuracy: 0.9889\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.1380 - accuracy: 0.9916\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1337 - accuracy: 0.9916\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.1309 - accuracy: 0.9833\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.1274 - accuracy: 0.9889\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.1247 - accuracy: 0.9889\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.1216 - accuracy: 0.9916\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.1174 - accuracy: 0.9889\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.1146 - accuracy: 0.9916\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.1119 - accuracy: 0.9889\n",
      "Enter the seed text: Pizza is undoubtedly\n",
      "Enter the number of next words to generate: 8\n",
      "1/1 [==============================] - 1s 853ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Next predicted words: Pizza is undoubtedly one of the world's most beloved foods renowned\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "def file_to_sentence_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Splitting the text into sentences using\n",
    "    # delimiters like '.', '?', and '!'\n",
    "    sentences = [sentence.strip() for sentence in re.split(r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def get_user_input():\n",
    "    seed_text = input(\"Enter the seed text: \")\n",
    "    next_words = int(input(\"Enter the number of next words to generate: \"))\n",
    "    return seed_text, next_words\n",
    "\n",
    "file_path = \"C:/Users/ADMIN/Documents/pizza.txt\"\n",
    "text_data = file_to_sentence_list(file_path)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences and split into predictors and label\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(\n",
    "    input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "\n",
    "# Convert target data to one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    LSTM(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)\n",
    "\n",
    "# Generate next word predictions\n",
    "seed_text, next_words = get_user_input()\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences(\n",
    "        [token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list)\n",
    "    predicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
    "    seed_text += \" \" + predicted_word\n",
    "\n",
    "print(\"Next predicted words:\", seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961d36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
